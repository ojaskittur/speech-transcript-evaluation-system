{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing dependencies","metadata":{}},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y openjdk-17-jdk-headless\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n\n!pip install sentence-transformers language-tool-python vaderSentiment textstat\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T16:39:58.420704Z","iopub.execute_input":"2025-11-22T16:39:58.421013Z","iopub.status.idle":"2025-11-22T16:42:32.424840Z","shell.execute_reply.started":"2025-11-22T16:39:58.420991Z","shell.execute_reply":"2025-11-22T16:42:32.423274Z"}},"outputs":[{"name":"stdout","text":"Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \nGet:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nHit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nGet:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\nGet:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]\nGet:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,532 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,876 kB]\nGet:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,290 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\nGet:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,151 kB]\nGet:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,475 kB]\nGet:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,832 kB]\nFetched 37.4 MB in 4s (9,466 kB/s)                           \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  openjdk-17-jre-headless\nSuggested packages:\n  openjdk-17-demo openjdk-17-source libnss-mdns fonts-dejavu-extra\n  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n  | fonts-wqy-zenhei fonts-indic\nThe following NEW packages will be installed:\n  openjdk-17-jdk-headless openjdk-17-jre-headless\n0 upgraded, 2 newly installed, 0 to remove and 176 not upgraded.\nNeed to get 120 MB of archives.\nAfter this operation, 272 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [48.3 MB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [71.3 MB]\nFetched 120 MB in 6s (21.5 MB/s)                   \nSelecting previously unselected package openjdk-17-jre-headless:amd64.\n(Reading database ... 128639 files and directories currently installed.)\nPreparing to unpack .../openjdk-17-jre-headless_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\nUnpacking openjdk-17-jre-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\nSelecting previously unselected package openjdk-17-jdk-headless:amd64.\nPreparing to unpack .../openjdk-17-jdk-headless_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\nUnpacking openjdk-17-jdk-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\nSetting up openjdk-17-jre-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\nSetting up openjdk-17-jdk-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting language-tool-python\n  Downloading language_tool_python-3.0.0-py3-none-any.whl.metadata (17 kB)\nCollecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nCollecting textstat\n  Downloading textstat-0.7.11-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.5)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (7.1.3)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from textstat) (3.9.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->textstat) (8.3.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->textstat) (1.5.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.10.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading language_tool_python-3.0.0-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading textstat-0.7.11-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, vaderSentiment, textstat, nvidia-cusparse-cu12, nvidia-cudnn-cu12, language-tool-python, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed language-tool-python-3.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyphen-0.17.2 textstat-0.7.11 vaderSentiment-3.3.2\nCollecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Imports & Rubric Configuration","metadata":{}},{"cell_type":"code","source":"import re\nimport spacy\nimport numpy as np\nimport language_tool_python\nfrom sentence_transformers import SentenceTransformer, util\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom sentence_transformers import CrossEncoder  \nfrom textstat import textstat\n\nprint(\"Loading models...\")\nnlp = spacy.load(\"en_core_web_sm\")\nsbert_model = SentenceTransformer('all-MiniLM-L6-v2')\ngrammar_tool = language_tool_python.LanguageTool('en-US')\nsentiment_analyzer = SentimentIntensityAnalyzer()\nnli_model = CrossEncoder('cross-encoder/stsb-distilroberta-base')\nprint(\"Models loaded.\")\n\nRUBRIC = {\n    \"salutation\": {\n        \"normal\": [\"hi\", \"hello\"],\n        \"good\": [\"good morning\", \"good afternoon\", \"good evening\", \"good day\", \"hello everyone\"],\n        \"excellent\": [\"excited to introduce\", \"feeling great\", \"pleasure to introduce\"]\n    },\n    \"content\": {\n        \"must_have\": {\n            \"points\": 4, \n            \"topics\": [\"Name\", \"Age\", \"School/Class\", \"Family\", \"Hobbies/Interests\"]\n        },\n        \"good_to_have\": {\n            \"points\": 2, \n            \"topics\": [\"Origin/Location\", \"Ambition/Goal\", \"Fun Fact/Unique\", \"Strengths\", \"Achievements\"]\n        }\n    },\n    \"speech_rate\": {\n        \"fast_threshold\": 160,\n        \"ideal_min\": 111,\n        \"ideal_max\": 140,\n        \"slow_threshold\": 80\n    },\n    \"fillers\": [\"um\", \"uh\", \"like\", \"you know\", \"actually\", \"basically\", \"right\", \"i mean\", \"well\", \"kinda\", \"sort of\", \"hmm\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T19:40:57.193942Z","iopub.execute_input":"2025-11-22T19:40:57.194382Z","iopub.status.idle":"2025-11-22T19:41:04.321119Z","shell.execute_reply.started":"2025-11-22T19:40:57.194357Z","shell.execute_reply":"2025-11-22T19:41:04.320315Z"}},"outputs":[{"name":"stdout","text":"Loading models...\n","output_type":"stream"},{"name":"stderr","text":"WARNING:language_tool_python.server:Unclosed server (server still running at http://127.0.0.1:8353/v2/). Closing it now.\n","output_type":"stream"},{"name":"stdout","text":"Models loaded.\n","output_type":"stream"}],"execution_count":132},{"cell_type":"markdown","source":"# Scoring Logic Engines","metadata":{}},{"cell_type":"code","source":"class IntroductionScorer:\n    def __init__(self, transcript_text, audio_duration_sec=None):\n        self.text = transcript_text\n        self.doc = nlp(transcript_text)\n        self.provided_duration = audio_duration_sec\n        \n        self.duration_min = (audio_duration_sec / 60) if audio_duration_sec else 0\n        self.sentences = [sent.text.strip() for sent in self.doc.sents]\n        self.words = [token.text.lower() for token in self.doc if not token.is_punct]\n        self.total_words = len(self.words)\n\n    def score_salutation(self):\n        text_lower = self.text.lower()\n        score = 0\n        feedback = \"No salutation found.\"\n        \n        for phrase in RUBRIC[\"salutation\"][\"excellent\"]:\n            if phrase in text_lower:\n                return 5, f\"Excellent salutation used: '{phrase}'\"\n        \n        for phrase in RUBRIC[\"salutation\"][\"good\"]:\n            if phrase in text_lower:\n                return 4, f\"Good salutation used: '{phrase}'\"\n                \n        for word in RUBRIC[\"salutation\"][\"normal\"]:\n            if word in text_lower:\n                return 2, \"Basic salutation used (Hi/Hello). Try to be more formal.\"\n                \n        return 0, feedback\n\n    def score_content(self):\n        scores = 0\n        feedback = []\n\n        regex_name = r\"\\b(name\\s+is|i\\s+am|i[\\s'’]*m|myself|this\\s+is)\\s+([A-Z])\"\n        regex_age = r\"\\b(\\d+|thirteen|fourteen|fifteen|sixteen)\\s*(-)?\\s*(years|yrs)\\b\"\n        regex_school = r\"\\b(class|grade|standard|school|college|university|study|student)\\b\"\n\n        if re.search(regex_name, self.text, re.IGNORECASE):\n            scores += 4; feedback.append(\"[+] Name\")\n        else: feedback.append(\"[-] Name\")\n\n        if re.search(regex_age, self.text, re.IGNORECASE):\n            scores += 4; feedback.append(\"[+] Age\")\n        else: feedback.append(\"[-] Age\")\n\n        if re.search(regex_school, self.text, re.IGNORECASE):\n            scores += 4; feedback.append(\"[+] School\")\n        else: feedback.append(\"[-] School\")\n\n        def check_topic_robust(topic, regex, anchors, use_ai=True):\n            if re.search(regex, self.text, re.IGNORECASE): return True\n            \n            if use_ai and self.sentences:\n                topic_emb = sbert_model.encode(anchors, convert_to_tensor=True)\n                text_emb = sbert_model.encode(self.sentences, convert_to_tensor=True)\n                best_score = float(util.cos_sim(text_emb, topic_emb).max())\n                return best_score > 0.35\n            return False\n\n        if check_topic_robust(\"Family\", r\"\\b(family|parents|mother|father|siblings)\\b\", [\"My family\", \"I live with\"]):\n            scores += 4; feedback.append(\"[+] Family\")\n        else: feedback.append(\"[-] Family\")\n\n        if check_topic_robust(\"Hobbies\", r\"\\b(hobby|hobbies|enjoy|like\\s+(to|playing|reading)|pastime)\\b\", [\"My hobby is\", \"I enjoy\"]):\n            scores += 4; feedback.append(\"[+] Hobbies\")\n        else: feedback.append(\"[-] Hobbies\")\n\n        bonuses = {\n            \"Ambition\": (r\"\\b(goal|ambition|dream|want\\s+to\\s+be)\\b\", [\"I want to become\"], True),\n            \"Strength\": (r\"\\b(strength|good\\s+at|confident)\\b\", [\"My strength is\"], True),\n            \"Unique\": (r\"\\b(unique|special|fun\\s+fact)\\b\", [\"fun fact\"], True),\n            \n            \"Origin\": (r\"\\b(i\\s+am\\s+from|i['’]m\\s+from|originally\\s+from|live\\s+in|living\\s+in|born\\s+in|hometown|native)\\b\", [], False),\n            \n            \"Achievements\": (r\"\\b(won|achievement|award)\\b\", [\"I won\"], True)\n        }\n\n        for topic, (reg, anc, use_ai_flag) in bonuses.items():\n            if check_topic_robust(topic, reg, anc, use_ai=use_ai_flag):\n                scores += 2; feedback.append(f\"[+] {topic}\")\n\n        return min(30, scores), \", \".join(feedback)\n\n    def score_flow(self):\n        anchors = {\n            \"salutation\": [\"Hello everyone\", \"Good morning\", \"Hi\", \"Greetings\"],\n            \"intro\": [\"My name is\", \"I am\", \"I'm\", \"I’m\", \"Myself\", \"This is\"],\n            \"closing\": [\"Thank you\", \"Thanks\", \"That is all\", \"The end\"],\n            \"body\": [\"family\", \"mother\", \"school\", \"class\", \"hobby\", \"playing\", \"dream\", \"goal\"]\n        }\n        if not self.sentences: return 0, \"No text\"\n        \n        text_emb = sbert_model.encode(self.sentences, convert_to_tensor=True)\n        \n        def get_idx(key, thresh=0.25):\n            anc = sbert_model.encode(anchors[key], convert_to_tensor=True)\n            sims = util.cos_sim(text_emb, anc).max(dim=1).values\n            best_idx = int(sims.argmax())\n            best_score = float(sims.max())\n            return best_idx, best_score > thresh\n\n        idx_s, has_s = get_idx(\"salutation\", 0.25)\n        idx_i, has_i = get_idx(\"intro\", 0.25)\n        idx_c, has_c = get_idx(\"closing\", 0.30) \n        \n        has_body = False\n        if has_i and has_c and idx_c > idx_i: \n             if idx_c - idx_i >= 1:\n                 mid_sents = self.sentences[idx_i+1 : idx_c]\n                 if mid_sents:\n                     mid_emb = sbert_model.encode(mid_sents, convert_to_tensor=True)\n                     bod_emb = sbert_model.encode(anchors[\"body\"], convert_to_tensor=True)\n                     if util.cos_sim(mid_emb, bod_emb).max() > 0.25: has_body = True\n\n        debug_info = f\"(Indices: Sal={idx_s if has_s else 'X'}, Intro={idx_i if has_i else 'X'}, End={idx_c if has_c else 'X'})\"\n\n        if has_s and has_c:\n            if has_i:\n                if idx_s <= idx_i < idx_c:\n                    return (5, \"Perfect Flow\") if has_body else (5, \"Good Flow (Short body)\")\n                if idx_i == idx_c:\n                    return 0, f\"Disordered: Introduction and Closing are detected in same sentence. {debug_info}\"\n            \n            elif idx_s < idx_c:\n                return (5, \"Good Flow\") if has_body else (5, \"Acceptable Flow\")\n                \n        return 0, f\"Flow disordered. {debug_info}\"\n\n    def score_speech_rate(self):\n        if not self.provided_duration:\n            return 10, \"Duration not provided (Assumed Ideal)\"\n            \n        wpm = self.total_words / self.duration_min if self.duration_min > 0 else 0\n        \n        if 111 <= wpm <= 140: return 10, f\"Ideal ({int(wpm)} WPM)\"\n        if 81 <= wpm <= 160: return 6, f\"Acceptable ({int(wpm)} WPM)\"\n        if wpm>140:\n            return 2, f\"Too Fast ({int(wpm)} WPM)\"\n        if wpm<81:\n            return 2, f\"Too slow ({int(wpm)} WPM)\"\n\n    def score_grammar(self):\n        try:\n            matches = grammar_tool.check(self.text)\n            scoring_errors = []\n            ignored_issues = []\n            \n            for m in matches:\n                rid = getattr(m, 'ruleId', '').upper()\n                msg = getattr(m, 'message', '').lower()\n                replacements = getattr(m, 'replacements', [])\n                \n                offset = getattr(m, 'offset', 0)\n                length = getattr(m, 'errorLength', getattr(m, 'length', 5))\n                error_text = self.text[offset : offset + length]\n                \n                is_ignored = False\n                \n                if replacements:\n                    top_rep = replacements[0]\n                    if \"-\" in top_rep and top_rep.replace(\"-\", \"\") == error_text.replace(\" \", \"\"):\n                        is_ignored = True\n                \n                ignore_keywords = [\n                    \"hyphen\", \"compound\", \"joined\", \"whitespace\", \"comma\", \"punctuation\",\n                    \"spelling\", \"typo\", \"morfologik\", \"uppercase\", \"capitalization\",\n                    \"repetition\", \"consecutive\", \"successive\", \"same word\", \n                    \"style\", \"wordiness\", \"sentence start\", \"rewording\", \"thesaurus\"\n                ]\n                \n                if any(k in msg or k in rid.lower() for k in ignore_keywords):\n                    is_ignored = True\n\n                if is_ignored: ignored_issues.append(m)\n                else: scoring_errors.append(m)\n            \n            err_count = len(scoring_errors)\n            errors_per_100 = (err_count / self.total_words) * 100 if self.total_words > 0 else 0\n            \n            grammar_metric = 1 - min(errors_per_100 / 5, 1)\n            \n            if grammar_metric > 0.9: s=10; g=\"Flawless\"\n            elif grammar_metric >= 0.7: s=8; g=\"Good\"\n            elif grammar_metric >= 0.5: s=6; g=\"Average\"\n            elif grammar_metric >= 0.3: s=4; g=\"Needs Improvement\"\n            else: s=2; g=\"Poor\"\n            \n            fb_lines = []\n            fb_lines.append(f\"{g} (Score: {s}/10)\")\n            fb_lines.append(\"NOTE: Spelling, hyphens, punctuation, and style ignored.\")\n            \n            if scoring_errors:\n                fb_lines.append(f\"\\n[CRITICAL GRAMMAR ERRORS] ({len(scoring_errors)} found):\")\n                for m in scoring_errors[:3]:\n                    off = getattr(m, 'offset', 0)\n                    ln = getattr(m, 'errorLength', getattr(m, 'length', 5))\n                    ctx = self.text[off : off+ln+10].replace('\\n', ' ')\n                    fb_lines.append(f\"   - {m.message} (Context: '...{ctx}...')\")\n            else:\n                fb_lines.append(\"\\n[CRITICAL GRAMMAR ERRORS]: None.\")\n\n            if ignored_issues:\n                fb_lines.append(f\"\\n[IGNORED ISSUES] ({len(ignored_issues)} found):\")\n                for m in ignored_issues[:3]:\n                    msg = getattr(m, 'message', 'Issue')\n                    off = getattr(m, 'offset', 0)\n                    ln = getattr(m, 'errorLength', getattr(m, 'length', 5))\n                    ctx = self.text[off : off+ln+10].replace('\\n', ' ')\n                    fb_lines.append(f\"   - {msg} (Context: '...{ctx}...')\")\n            \n            return s, \"\\n\".join(fb_lines)\n            \n        except Exception as e:\n            return 5, f\"Error: {str(e)}\"\n\n    def score_vocabulary(self):\n        distinct_words = len(set(self.words))\n        ttr = distinct_words / self.total_words if self.total_words > 0 else 0\n        \n        if ttr >= 0.9: return 10, f\"Excellent variety (TTR: {ttr:.2f})\"\n        elif ttr >= 0.7: return 8, f\"Good variety (TTR: {ttr:.2f})\"\n        elif ttr >= 0.5: return 6, f\"Average variety (TTR: {ttr:.2f})\"\n        elif ttr >= 0.3: return 4, f\"Repetitive (TTR: {ttr:.2f})\"\n        else: return 2, f\"Very repetitive (TTR: {ttr:.2f})\"\n\n    def score_clarity(self):\n        filler_count = 0\n        for word in self.words:\n            if word in RUBRIC[\"fillers\"]:\n                filler_count += 1\n        \n        filler_rate = (filler_count / self.total_words) * 100\n        \n        if filler_rate <= 3: return 15, f\"Clear speech ({filler_count} fillers)\"\n        elif filler_rate <= 6: return 12, f\"Mostly clear ({filler_count} fillers)\"\n        elif filler_rate <= 9: return 9, f\"Some hesitation ({filler_count} fillers)\"\n        elif filler_rate <= 12: return 6, f\"Hesitant ({filler_count} fillers)\"\n        else: return 3, f\"Distracted by fillers ({filler_count} fillers)\"\n\n    def score_engagement(self):\n        vs = sentiment_analyzer.polarity_scores(self.text)\n        \n        prob = (vs['compound'] + 1) / 2\n        \n        high_energy_kws = [\n            \"excited\", \"thrilled\", \"passionate\", \"delighted\", \"honor\", \n            \"love\", \"amazing\", \"wonderful\", \"fantastic\", \"energetic\",\n            \"grateful\", \"confident\", \"pleasure\"\n        ]\n        \n        has_enthusiasm = any(w in self.text.lower() for w in high_energy_kws)\n        \n        if prob >= 0.9 and not has_enthusiasm:\n            prob = 0.88 \n            \n        if prob >= 0.9:\n            return 15, f\"Very Engaging (Sentiment: {prob:.2f})\"\n        elif prob >= 0.7:\n            return 12, f\"Positive (Sentiment: {prob:.2f})\"\n        elif prob >= 0.5:\n            return 9, f\"Neutral (Sentiment: {prob:.2f})\"\n        elif prob >= 0.3:\n            return 6, f\"Slightly Negative (Sentiment: {prob:.2f})\"\n        else:\n            return 3, f\"Negative (Sentiment: {prob:.2f})\"\n\n    def calculate_overall_score(self):\n        \n        s_salutation, f_salutation = self.score_salutation()\n        s_content, f_content = self.score_content()\n        s_flow, f_flow = self.score_flow()\n        s_rate, f_rate = self.score_speech_rate()\n        s_grammar, f_grammar = self.score_grammar()\n        s_vocab, f_vocab = self.score_vocabulary()\n        s_clarity, f_clarity = self.score_clarity()\n        s_engage, f_engage = self.score_engagement()\n        \n        total_score = (\n            s_salutation + s_content + s_flow + s_rate + \n            s_grammar + s_vocab + s_clarity + s_engage\n        )\n        \n        return {\n            \"Total Score\": total_score,\n            \"Breakdown\": {\n                \"Salutation\": {\"score\": s_salutation, \"max\": 5, \"feedback\": f_salutation},\n                \"Content & Structure\": {\"score\": s_content, \"max\": 30, \"feedback\": f_content},\n                \"Flow\": {\"score\": s_flow, \"max\": 5, \"feedback\": f_flow},\n                \"Speech Rate\": {\"score\": s_rate, \"max\": 10, \"feedback\": f_rate},\n                \"Grammar\": {\"score\": s_grammar, \"max\": 10, \"feedback\": f_grammar},\n                \"Vocabulary\": {\"score\": s_vocab, \"max\": 10, \"feedback\": f_vocab},\n                \"Clarity (Fillers)\": {\"score\": s_clarity, \"max\": 15, \"feedback\": f_clarity},\n                \"Engagement\": {\"score\": s_engage, \"max\": 15, \"feedback\": f_engage},\n            }\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T19:41:07.357803Z","iopub.execute_input":"2025-11-22T19:41:07.358084Z","iopub.status.idle":"2025-11-22T19:41:07.398550Z","shell.execute_reply.started":"2025-11-22T19:41:07.358066Z","shell.execute_reply":"2025-11-22T19:41:07.397863Z"}},"outputs":[],"execution_count":133},{"cell_type":"markdown","source":"# Testing on transcript","metadata":{}},{"cell_type":"code","source":"transcript = \"\"\"\nHello everyone, myself Muskan, studying in class 8th B section from Christ Public School. \nI am 13 years old. I live with my family. There are 3 people in my family, me, my mother and my father.\nOne special thing about my family is that they are very kind hearted to everyone and soft spoken. One thing I really enjoy is play, playing cricket and taking wickets.\nA fun fact about me is that I see in mirror and talk by myself. One thing people don't know about me is that I once stole a toy from one of my cousin.\n My favorite subject is science because it is very interesting. Through science I can explore the whole world and make the discoveries and improve the lives of others. \nThank you for listening.\n\"\"\"\n\nscorer = IntroductionScorer(transcript)\n\nresults = scorer.calculate_overall_score()\n\nimport json\nprint(f\"--- FINAL SCORE: {results['Total Score']} / 100 ---\\n\")\nprint(json.dumps(results['Breakdown'], indent=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T19:42:36.265188Z","iopub.execute_input":"2025-11-22T19:42:36.266012Z","iopub.status.idle":"2025-11-22T19:42:37.007816Z","shell.execute_reply.started":"2025-11-22T19:42:36.265988Z","shell.execute_reply":"2025-11-22T19:42:37.006872Z"}},"outputs":[{"name":"stdout","text":"--- FINAL SCORE: 86 / 100 ---\n\n{\n    \"Salutation\": {\n        \"score\": 4,\n        \"max\": 5,\n        \"feedback\": \"Good salutation used: 'hello everyone'\"\n    },\n    \"Content & Structure\": {\n        \"score\": 24,\n        \"max\": 30,\n        \"feedback\": \"[+] Name, [+] Age, [+] School, [+] Family, [+] Hobbies, [+] Ambition, [+] Unique\"\n    },\n    \"Flow\": {\n        \"score\": 5,\n        \"max\": 5,\n        \"feedback\": \"Perfect Flow\"\n    },\n    \"Speech Rate\": {\n        \"score\": 10,\n        \"max\": 10,\n        \"feedback\": \"Duration not provided (Assumed Ideal)\"\n    },\n    \"Grammar\": {\n        \"score\": 10,\n        \"max\": 10,\n        \"feedback\": \"Flawless (Score: 10/10)\\nNOTE: Spelling, hyphens, punctuation, and style ignored.\\n\\n[CRITICAL GRAMMAR ERRORS]: None.\\n\\n[IGNORED ISSUES] (4 found):\\n   - Possible spelling mistake found. (Context: '...Muskan, studyin...')\\n   - This expression is normally spelled as one or with a hyphen. (Context: '...kind hearted to...')\\n   - This word is normally spelled with a hyphen. (Context: '...soft spoken. On...')\"\n    },\n    \"Vocabulary\": {\n        \"score\": 6,\n        \"max\": 10,\n        \"feedback\": \"Average variety (TTR: 0.63)\"\n    },\n    \"Clarity (Fillers)\": {\n        \"score\": 15,\n        \"max\": 15,\n        \"feedback\": \"Clear speech (0 fillers)\"\n    },\n    \"Engagement\": {\n        \"score\": 12,\n        \"max\": 15,\n        \"feedback\": \"Positive (Sentiment: 0.88)\"\n    }\n}\n","output_type":"stream"}],"execution_count":136}]}